{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "from cv2 import cv2 as cv\n",
    "import numpy as np\n",
    "from imutils import contours\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import cmp_to_key\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import os, os.path\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def prepareHistData(img, dst):\n",
    "    # generate histogram\n",
    "    hist, bins = np.histogram(img.ravel(), 256, [0, 256])\n",
    "\n",
    "    # scale it to fit the shape of \"canvas\"\n",
    "    maximum = hist.max()\n",
    "    if maximum == 0:\n",
    "        maximum = 1\n",
    "    hist = hist / maximum * dst.shape[0]\n",
    "\n",
    "    # now append X axis by stacking transposed histogram and linspace\n",
    "    stack = np.vstack((np.linspace(0, dst.shape[1], 256), hist.reshape(-1))).T\n",
    "\n",
    "    # this data is still flipped; unflip it\n",
    "    stack[:, 1] = dst.shape[0] - stack[:, 1]\n",
    "\n",
    "    return stack\n",
    "\n",
    "\n",
    "def plotBinHistogram(img, dst, color=(0, 255, 255)):\n",
    "    stack = prepareHistData(img, dst)\n",
    "    bin_w = dst.shape[1] / 255\n",
    "\n",
    "    # bruh this python loop\n",
    "    for i in range(256):\n",
    "        cv.rectangle(dst, (np.int32(stack[i][0] - bin_w/2), np.int32(stack[i][1])),\n",
    "                     (np.int32(stack[i][0] + bin_w/2), np.int32(dst.shape[0])), color, -1)\n",
    "\n",
    "\n",
    "def plotLineHistogram(img, dst, color=(0, 255, 255)):\n",
    "    stack = prepareHistData(img, dst)\n",
    "\n",
    "    cv.polylines(dst, [np.int32(stack)], False, color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('../imgs/an/test/b1.jpg')\n",
    "#img = cv.resize(img, (200, 200))\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2HSV)[:,:,0]\n",
    "\n",
    "data  = cv.calcHist([img], [0], None, [256], [0, 256]) #img.ravel()\n",
    "\n",
    "histogram_canvas = np.zeros((200, 256, 3), np.uint8)\n",
    "plotBinHistogram(img, histogram_canvas)\n",
    "\n",
    "while True:\n",
    "    cv.imshow(\"histogram\", histogram_canvas)\n",
    "    k = cv.waitKey(0) & 0xFF\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 200\n",
    "histSize = 256\n",
    "histRange = (0, 256) # the upper boundary is exclusive\n",
    "accumulate = False\n",
    "\n",
    "def load_img(path):\n",
    "    img = cv.imread(path)\n",
    "    #img = cv.resize(img, (size, size))\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2HSV)[:,:,0]\n",
    "    \n",
    "    data  = cv.calcHist([img], [0], None, [256], [0, 256]) #img.ravel()\n",
    "\n",
    "    data = data[:, 0]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 256)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for f in os.listdir('../imgs/an/badger'):\n",
    "    data = load_img('../imgs/an/badger/' + f)\n",
    "    X.append(data)\n",
    "    y.append(0)\n",
    "    # print(data)\n",
    "\n",
    "for f in os.listdir('../imgs/an/chipmunk'):\n",
    "    data = load_img('../imgs/an/chipmunk/' + f)\n",
    "    X.append(data)\n",
    "    y.append(1)\n",
    "    # print(data)\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_embedded = X# pca.transform(X)# tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, max_depth=2, n_estimators=200,\n",
       "                           random_state=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf  = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=2, random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_label(id):\n",
    "    return 'badger' if id == 0 else 'chipmuck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = np.asarray([load_img('../imgs/an/test/b2.jpg'), load_img('../imgs/an/test/c1.jpg')])\n",
    "test_b = test_X#pca.transform(test_X)\n",
    "clf.predict(test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d083ba42aae9f9d11237e0be732a28f2bf1430ce107b8104c51f88075f06857"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
